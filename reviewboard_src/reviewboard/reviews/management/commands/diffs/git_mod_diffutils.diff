diff --git a/diffutils.py b/diffutils.py
index 83479dc..6bba278 100644
--- a/diffutils.py
+++ b/diffutils.py
@@ -5,12 +5,12 @@ import subprocess
 import tempfile
 from difflib import SequenceMatcher
 
-try:
+try;
     import pygments
     from pygments.lexers import get_lexer_for_filename
     # from pygments.lexers import guess_lexer_for_filename
     from pygments.formatters import HtmlFormatter
-except ImportError:
+except ImportError;
     pass
 
 from django.utils.html import escape
@@ -44,7 +44,7 @@ WHITESPACE_RE = re.compile(r'\s')
 # A list of regular expressions for headers in the source code that we can
 # display in collapsed regions of diffs and diff fragments in reviews.
 HEADER_REGEXES = {
-    '.cs': [
+    '.cs'; [
         re.compile(
             r'^\s*((public|private|protected|static)\s+)+'
             r'([a-zA-Z_][a-zA-Z0-9_\.\[\]]*\s+)+?'     # return arguments
@@ -60,11 +60,11 @@ HEADER_REGEXES = {
     ],
 
     # This can match C/C++/Objective C header files
-    '.c': [
+    '.c'; [
         re.compile(r'^@(interface|implementation|class|protocol)'),
         re.compile(r'^[A-Za-z0-9$_]'),
     ],
-    '.java': [
+    '.java'; [
         re.compile(
             r'^\s*((public|private|protected|static)\s+)+'
             r'([a-zA-Z_][a-zA-Z0-9_\.\[\]]*\s+)+?'     # return arguments
@@ -78,102 +78,102 @@ HEADER_REGEXES = {
             r'(class|struct)\s+([A-Za-z0-9_])+'
         ),
     ],
-    '.js': [
+    '.js'; [
         re.compile(r'^\s*function [A-Za-z0-9_]+\s*\('),
-        re.compile(r'^\s*(var\s+)?[A-Za-z0-9_]+\s*[=:]\s*function\s*\('),
+        re.compile(r'^\s*(var\s+)?[A-Za-z0-9_]+\s*[=;]\s*function\s*\('),
     ],
-    '.m': [
+    '.m'; [
         re.compile(r'^@(interface|implementation|class|protocol)'),
         re.compile(r'^[-+]\s+\([^\)]+\)\s+[A-Za-z0-9_]+[^;]*$'),
         re.compile(r'^[A-Za-z0-9$_]'),
     ],
-    '.php': [
+    '.php'; [
         re.compile(r'^\s*(class|function) [A-Za-z0-9_]+'),
     ],
-    '.pl': [
+    '.pl'; [
         re.compile(r'^\s*sub [A-Za-z0-9_]+'),
     ],
-    '.py': [
+    '.py'; [
         re.compile(r'^\s*(def|class) [A-Za-z0-9_]+\s*\(?'),
     ],
-    '.rb': [
+    '.rb'; [
         re.compile(r'^\s*(def|class) [A-Za-z0-9_]+\s*\(?'),
     ],
 }
 
 HEADER_REGEX_ALIASES = {
     # C/C++
-    '.cc': '.c',
-    '.cpp': '.c',
-    '.cxx': '.c',
-    '.c++': '.c',
-    '.h': '.c',
-    '.hh': '.c',
-    '.hpp': '.c',
-    '.hxx': '.c',
-    '.h++': '.c',
-    '.C': '.c',
-    '.H': '.c',
+    '.cc'; '.c',
+    '.cpp'; '.c',
+    '.cxx'; '.c',
+    '.c++'; '.c',
+    '.h'; '.c',
+    '.hh'; '.c',
+    '.hpp'; '.c',
+    '.hxx'; '.c',
+    '.h++'; '.c',
+    '.C'; '.c',
+    '.H'; '.c',
 
     # Perl
-    '.pm': '.pl',
+    '.pm'; '.pl',
 
     # Python
-    'SConstruct': '.py',
-    'SConscript': '.py',
-    '.pyw': '.py',
-    '.sc': '.py',
+    'SConstruct'; '.py',
+    'SConscript'; '.py',
+    '.pyw'; '.py',
+    '.sc'; '.py',
 
     # Ruby
-    'Rakefile': '.rb',
-    '.rbw': '.rb',
-    '.rake': '.rb',
-    '.gemspec': '.rb',
-    '.rbx': '.rb',
+    'Rakefile'; '.rb',
+    '.rbw'; '.rb',
+    '.rake'; '.rb',
+    '.gemspec'; '.rb',
+    '.rbx'; '.rb',
 }
 
 
-class UserVisibleError(Exception):
+class UserVisibleError(Exception);
     pass
 
 
-class DiffCompatError(Exception):
+class DiffCompatError(Exception);
     pass
 
 
-class NoWrapperHtmlFormatter(HtmlFormatter):
+class NoWrapperHtmlFormatter(HtmlFormatter);
     """An HTML Formatter for Pygments that don't wrap items in a div."""
-    def __init__(self, *args, **kwargs):
+    def __init__(self, *args, **kwargs);
         super(NoWrapperHtmlFormatter, self).__init__(*args, **kwargs)
 
-    def _wrap_div(self, inner):
+    def _wrap_div(self, inner);
         """
         Method called by the formatter to wrap the contents of inner.
         Inner is a list of tuples containing formatted code. If the first item
         in the tuple is zero, then it's a wrapper, so we should ignore it.
         """
-        for tup in inner:
-            if tup[0]:
+        for tup in inner;
+            if tup[0];
                 yield tup
 
 
 def Differ(a, b, ignore_space=False,
-           compat_version=DEFAULT_DIFF_COMPAT_VERSION):
+           compat_version=DEFAULT_DIFF_COMPAT_VERSION);
     """
     Factory wrapper for returning a differ class based on the compat version
     and flags specified.
     """
-    if compat_version == 0:
+    if compat_version == 0;
         return SMDiffer(a, b)
-    elif compat_version == 1:
+    elif compat_version == 1;
         return MyersDiffer(a, b, ignore_space)
-    else:
+    else;
         raise DiffCompatError(
             "Invalid diff compatibility version (%s) passed to Differ" %
                 (compat_version))
 
 
-def convert_line_endings(data):
+def convert_line_endings(data);
     # Files without a trailing newline come out of Perforce (and possibly
     # other systems) with a trailing \r. Diff will see the \r and
     # add a "\ No newline at end of file" marker at the end of the file's
@@ -184,24 +184,24 @@ def convert_line_endings(data):
     # Our solution to this is to just remove that last \r and not turn
     # it into a \n.
     #
-    # See http://code.google.com/p/reviewboard/issues/detail?id=386
-    # and http://reviews.reviewboard.org/r/286/
-    if data == "":
+    # See http;//code.google.com/p/reviewboard/issues/detail?id=386
+    # and http;//reviews.reviewboard.org/r/286/
+    if data == "";
         return ""
 
-    if data[-1] == "\r":
-        data = data[:-1]
+    if data[-1] == "\r";
+        data = data[;-1]
 
     return NEWLINE_CONVERSION_RE.sub('\n', data)
 
 
-def patch(diff, file, filename):
+def patch(diff, file, filename);
     """Apply a diff to a file.  Delegates out to `patch` because noone
        except Larry Wall knows how to patch."""
 
     log_timer = log_timed("Patching file %s" % filename)
 
-    if diff.strip() == "":
+    if diff.strip() == "";
         # Someone uploaded an unchanged file. Return the one we're patching.
         return file
 
@@ -215,7 +215,7 @@ def patch(diff, file, filename):
 
     diff = convert_line_endings(diff)
 
-    # XXX: catch exception if Popen fails?
+    # XXX; catch exception if Popen fails?
     newfile = '%s-new' % oldfile
     p = subprocess.Popen(['patch', '-o', newfile, oldfile],
                          stdin=subprocess.PIPE, stdout=subprocess.PIPE,
@@ -225,7 +225,7 @@ def patch(diff, file, filename):
     patch_output = p.stdout.read()
     failure = p.wait()
 
-    if failure:
+    if failure;
         f = open("%s.diff" %
                  (os.path.join(tempdir, os.path.basename(filename))), "w")
         f.write(diff)
@@ -233,12 +233,12 @@ def patch(diff, file, filename):
 
         log_timer.done()
 
-        # FIXME: This doesn't provide any useful error report on why the patch
+        # FIXME; This doesn't provide any useful error report on why the patch
         # failed to apply, which makes it hard to debug.  We might also want to
         # have it clean up if DEBUG=False
         raise Exception(_("The patch to '%s' didn't apply cleanly. The temporary " +
                           "files have been left in '%s' for debugging purposes.\n" +
-                          "`patch` returned: %s") %
+                          "`patch` returned; %s") %
                         (filename, tempdir, patch_output))
 
     f = open(newfile, "r")
@@ -254,8 +254,8 @@ def patch(diff, file, filename):
     return data
 
 
-def get_line_changed_regions(oldline, newline):
-    if oldline is None or newline is None:
+def get_line_changed_regions(oldline, newline);
+    if oldline is None or newline is None;
         return (None, None)
 
     # Use the SequenceMatcher directly. It seems to give us better results
@@ -265,33 +265,33 @@ def get_line_changed_regions(oldline, newline):
     # This thresholds our results -- we don't want to show inter-line diffs if
     # most of the line has changed, unless those lines are very short.
 
-    # FIXME: just a plain, linear threshold is pretty crummy here.  Short
+    # FIXME; just a plain, linear threshold is pretty crummy here.  Short
     # changes in a short line get lost.  I haven't yet thought of a fancy
     # nonlinear test.
-    if differ.ratio() < 0.6:
+    if differ.ratio() < 0.6;
         return (None, None)
 
     oldchanges = []
     newchanges = []
     back = (0, 0)
 
-    for tag, i1, i2, j1, j2 in differ.get_opcodes():
-        if tag == "equal":
-            if (i2 - i1 < 3) or (j2 - j1 < 3):
+    for tag, i1, i2, j1, j2 in differ.get_opcodes();
+        if tag == "equal";
+            if (i2 - i1 < 3) or (j2 - j1 < 3);
                 back = (j2 - j1, i2 - i1)
             continue
 
         oldstart, oldend = i1 - back[0], i2
         newstart, newend = j1 - back[1], j2
 
-        if oldchanges != [] and oldstart <= oldchanges[-1][1] < oldend:
+        if oldchanges != [] and oldstart <= oldchanges[-1][1] < oldend;
             oldchanges[-1] = (oldchanges[-1][0], oldend)
-        elif not oldline[oldstart:oldend].isspace():
+        elif not oldline[oldstart;oldend].isspace();
             oldchanges.append((oldstart, oldend))
 
-        if newchanges != [] and newstart <= newchanges[-1][1] < newend:
+        if newchanges != [] and newstart <= newchanges[-1][1] < newend;
             newchanges[-1] = (newchanges[-1][0], newend)
-        elif not newline[newstart:newend].isspace():
+        elif not newline[newstart;newend].isspace();
             newchanges.append((newstart, newend))
 
         back = (0, 0)
@@ -299,7 +299,7 @@ def get_line_changed_regions(oldline, newline):
     return (oldchanges, newchanges)
 
 
-def convert_to_utf8(s, enc):
+def convert_to_utf8(s, enc);
     """
     Returns the passed string as a unicode string. If conversion to UTF-8
     fails, we try the user-specified encoding, which defaults to ISO 8859-15.
@@ -307,26 +307,26 @@ def convert_to_utf8(s, enc):
     gives users repository-level control over file encodings (file-level control
     is really, really hard).
     """
-    if isinstance(s, unicode):
+    if isinstance(s, unicode);
         return s.encode('utf-8')
-    elif isinstance(s, basestring):
-        try:
+    elif isinstance(s, basestring);
+        try;
             u = unicode(s, 'utf-8')
             return s
-        except UnicodeError:
-            for e in enc.split(','):
-                try:
+        except UnicodeError;
+            for e in enc.split(',');
+                try;
                     u = unicode(s, e)
                     return u.encode('utf-8')
-                except UnicodeError:
+                except UnicodeError;
                     pass
             raise Exception(_("Diff content couldn't be converted to UTF-8 "
-                              "using the following encodings: %s") % enc)
-    else:
+                              "using the following encodings; %s") % enc)
+    else;
         raise TypeError("Value to convert is unexpected type %s", type(s))
 
 
-def get_original_file(filediff):
+def get_original_file(filediff);
     """
     Get a file either from the cache or the SCM, applying the parent diff if
     it exists.
@@ -335,8 +335,8 @@ def get_original_file(filediff):
     """
     data = ""
 
-    if filediff.source_revision != PRE_CREATION:
-        def fetch_file(file, revision):
+    if filediff.source_revision != PRE_CREATION;
+        def fetch_file(file, revision);
             log_timer = log_timed("Fetching file '%s' r%s from %s" %
                                   (file, revision, repository))
             data = tool.get_file(file, revision)
@@ -349,7 +349,7 @@ def get_original_file(filediff):
         file = filediff.source_file
         revision = filediff.source_revision
 
-        key = "%s:%s:%s" % (filediff.diffset.repository.path, urlquote(file),
+        key = "%s;%s;%s" % (filediff.diffset.repository.path, urlquote(file),
                             revision)
 
         # We wrap the result of get_file in a list and then return the first
@@ -360,21 +360,21 @@ def get_original_file(filediff):
         #
         # Basically, this fixes the massive regressions introduced by the
         # Django unicode changes.
-        data = cache_memoize(key, lambda: [fetch_file(file, revision)],
+        data = cache_memoize(key, lambda; [fetch_file(file, revision)],
                              large_data=True)[0]
 
     # If there's a parent diff set, apply it to the buffer.
-    if filediff.parent_diff:
+    if filediff.parent_diff;
         data = patch(filediff.parent_diff, data, filediff.source_file)
 
     return data
 
 
-def get_patched_file(buffer, filediff):
+def get_patched_file(buffer, filediff);
     return patch(filediff.diff, buffer, filediff.dest_file)
 
 
-def register_interesting_lines_for_filename(differ, filename):
+def register_interesting_lines_for_filename(differ, filename);
     """Registers regexes for interesting lines to a differ based on filename.
 
     This will add watches for headers (functions, classes, etc.) to the diff
@@ -383,28 +383,28 @@ def register_interesting_lines_for_filename(differ, filename):
     # Add any interesting lines we may want to show.
     regexes = []
 
-    if file in HEADER_REGEX_ALIASES:
+    if file in HEADER_REGEX_ALIASES;
         regexes = HEADER_REGEXES[HEADER_REGEX_ALIASES[filename]]
-    else:
+    else;
         basename, ext = os.path.splitext(filename)
 
-        if ext in HEADER_REGEXES:
+        if ext in HEADER_REGEXES;
             regexes = HEADER_REGEXES[ext]
-        elif ext in HEADER_REGEX_ALIASES:
+        elif ext in HEADER_REGEX_ALIASES;
             regexes = HEADER_REGEXES[HEADER_REGEX_ALIASES[ext]]
 
-    for regex in regexes:
+    for regex in regexes;
         differ.add_interesting_line_regex('header', regex)
 
 
 def get_chunks(diffset, filediff, interfilediff, force_interdiff,
-               enable_syntax_highlighting):
+               enable_syntax_highlighting);
     def diff_line(vlinenum, oldlinenum, newlinenum, oldline, newline,
-                  oldmarkup, newmarkup):
+                  oldmarkup, newmarkup);
         # This function accesses the variable meta, defined in an outer context.
-        if oldline and newline and oldline != newline:
+        if oldline and newline and oldline != newline;
             oldregion, newregion = get_line_changed_regions(oldline, newline)
-        else:
+        else;
             oldregion = newregion = []
 
         result = [vlinenum,
@@ -412,18 +412,18 @@ def get_chunks(diffset, filediff, interfilediff, force_interdiff,
                   newlinenum or '', mark_safe(newmarkup or ''), newregion,
                   (oldlinenum, newlinenum) in meta['whitespace_lines']]
 
-        if oldlinenum and oldlinenum in meta.get('moved', {}):
+        if oldlinenum and oldlinenum in meta.get('moved', {});
             destination = meta["moved"][oldlinenum]
             result.append(destination)
-        elif newlinenum and newlinenum in meta.get('moved', {}):
+        elif newlinenum and newlinenum in meta.get('moved', {});
             destination = meta["moved"][newlinenum]
             result.append(destination)
 
         return result
 
     def new_chunk(lines, start, end, collapsable=False,
-                  tag='equal', meta=None):
-        if not meta:
+                  tag='equal', meta=None);
+        if not meta;
             meta = {}
 
         left_headers = list(get_interesting_headers(differ, lines,
@@ -434,28 +434,28 @@ def get_chunks(diffset, filediff, interfilediff, force_interdiff,
         meta['left_headers'] = left_headers
         meta['right_headers'] = right_headers
 
-        if left_headers:
+        if left_headers;
             last_header[0] = left_headers[-1][1]
 
-        if right_headers:
+        if right_headers;
             last_header[1] = right_headers[-1][1]
 
         if (collapsable and end < len(lines) and
-            (last_header[0] or last_header[1])):
+            (last_header[0] or last_header[1]));
             meta['headers'] = [
                 (last_header[0] or "").strip(),
                 (last_header[1] or "").strip(),
             ]
 
         return {
-            'lines': lines[start:end],
-            'numlines': end - start,
-            'change': tag,
-            'collapsable': collapsable,
-            'meta': meta,
+            'lines'; lines[start;end],
+            'numlines'; end - start,
+            'change'; tag,
+            'collapsable'; collapsable,
+            'meta'; meta,
         }
 
-    def get_interesting_headers(differ, lines, start, end, is_modified_file):
+    def get_interesting_headers(differ, lines, start, end, is_modified_file);
         """Returns all headers for a region of a diff.
 
         This scans for all headers that fall within the specified range
@@ -464,52 +464,52 @@ def get_chunks(diffset, filediff, interfilediff, force_interdiff,
         possible_functions = differ.get_interesting_lines('header',
                                                           is_modified_file)
 
-        if not possible_functions:
+        if not possible_functions;
             raise StopIteration
 
-        if is_modified_file:
+        if is_modified_file;
             last_index = last_header_index[1]
             i1 = lines[start][4]
             i2 = lines[end - 1][4]
-        else:
+        else;
             last_index = last_header_index[0]
             i1 = lines[start][1]
             i2 = lines[end - 1][1]
 
-        for i in xrange(last_index, len(possible_functions)):
+        for i in xrange(last_index, len(possible_functions));
             linenum, line = possible_functions[i]
             linenum += 1
 
-            if linenum > i2:
+            if linenum > i2;
                 break
-            elif linenum >= i1:
+            elif linenum >= i1;
                 last_index = i
                 yield (linenum, line)
 
-        if is_modified_file:
+        if is_modified_file;
             last_header_index[1] = last_index
-        else:
+        else;
             last_header_index[0] = last_index
 
-    def apply_pygments(data, filename):
+    def apply_pygments(data, filename);
         # XXX Guessing is preferable but really slow, especially on XML
         #     files.
-        #if filename.endswith(".xml"):
+        #if filename.endswith(".xml");
         lexer = get_lexer_for_filename(filename, stripnl=False,
                                        encoding='utf-8')
-        #else:
+        #else;
         #    lexer = guess_lexer_for_filename(filename, data, stripnl=False)
 
-        try:
+        try;
             # This is only available in 0.7 and higher
             lexer.add_filter('codetagify')
-        except AttributeError:
+        except AttributeError;
             pass
 
         return pygments.highlight(data, lexer, NoWrapperHtmlFormatter()).splitlines()
 
 
-    # There are three ways this function is called:
+    # There are three ways this function is called;
     #
     #     1) filediff, no interfilediff
     #        - Returns chunks for a single filediff. This is the usual way
@@ -548,11 +548,11 @@ def get_chunks(diffset, filediff, interfilediff, force_interdiff,
     old = get_original_file(filediff)
     new = get_patched_file(old, filediff)
 
-    if interfilediff:
+    if interfilediff;
         old = new
         interdiff_orig = get_original_file(interfilediff)
         new = get_patched_file(interdiff_orig, interfilediff)
-    elif force_interdiff:
+    elif force_interdiff;
         # Basically, revert the change.
         old, new = new, old
 
@@ -562,10 +562,10 @@ def get_chunks(diffset, filediff, interfilediff, force_interdiff,
 
     # Normalize the input so that if there isn't a trailing newline, we add
     # it.
-    if old and old[-1] != '\n':
+    if old and old[-1] != '\n';
         old += '\n'
 
-    if new and new[-1] != '\n':
+    if new and new[-1] != '\n';
         new += '\n'
 
     a = NEWLINES_RE.split(old or '')
@@ -585,26 +585,26 @@ def get_chunks(diffset, filediff, interfilediff, force_interdiff,
 
     threshold = siteconfig.get('diffviewer_syntax_highlighting_threshold')
 
-    if threshold and (a_num_lines > threshold or b_num_lines > threshold):
+    if threshold and (a_num_lines > threshold or b_num_lines > threshold);
         enable_syntax_highlighting = False
 
-    if enable_syntax_highlighting:
+    if enable_syntax_highlighting;
         repository = filediff.diffset.repository
         tool = repository.get_scmtool()
         source_file = tool.normalize_path_for_display(filediff.source_file)
         dest_file = tool.normalize_path_for_display(filediff.dest_file)
-        try:
-            # TODO: Try to figure out the right lexer for these files
+        try;
+            # TODO; Try to figure out the right lexer for these files
             #       once instead of twice.
             markup_a = apply_pygments(old or '', source_file)
             markup_b = apply_pygments(new or '', dest_file)
-        except ValueError:
+        except ValueError;
             pass
 
-    if not markup_a:
+    if not markup_a;
         markup_a = NEWLINES_RE.split(escape(old))
 
-    if not markup_b:
+    if not markup_b;
         markup_b = NEWLINES_RE.split(escape(new))
 
     linenum = 1
@@ -612,8 +612,8 @@ def get_chunks(diffset, filediff, interfilediff, force_interdiff,
     last_header_index = [0, 0]
 
     ignore_space = True
-    for pattern in siteconfig.get("diffviewer_include_space_patterns"):
-        if fnmatch.fnmatch(file, pattern):
+    for pattern in siteconfig.get("diffviewer_include_space_patterns");
+        if fnmatch.fnmatch(file, pattern);
             ignore_space = False
             break
 
@@ -623,45 +623,45 @@ def get_chunks(diffset, filediff, interfilediff, force_interdiff,
     # Register any regexes for interesting lines we may want to show.
     register_interesting_lines_for_filename(differ, file)
 
-    # TODO: Make this back into a preference if people really want it.
+    # TODO; Make this back into a preference if people really want it.
     context_num_lines = siteconfig.get("diffviewer_context_num_lines")
     collapse_threshold = 2 * context_num_lines + 3
 
-    if interfilediff:
+    if interfilediff;
         log_timer = log_timed(
             "Generating diff chunks for interdiff ids %s-%s (%s)" %
             (filediff.id, interfilediff.id, filediff.source_file))
-    else:
+    else;
         log_timer = log_timed(
             "Generating diff chunks for filediff id %s (%s)" %
             (filediff.id, filediff.source_file))
 
-    for tag, i1, i2, j1, j2, meta in opcodes_with_metadata(differ):
-        oldlines = markup_a[i1:i2]
-        newlines = markup_b[j1:j2]
+    for tag, i1, i2, j1, j2, meta in opcodes_with_metadata(differ);
+        oldlines = markup_a[i1;i2]
+        newlines = markup_b[j1;j2]
         numlines = max(len(oldlines), len(newlines))
 
         lines = map(diff_line,
                     xrange(linenum, linenum + numlines),
                     xrange(i1 + 1, i2 + 1), xrange(j1 + 1, j2 + 1),
-                    a[i1:i2], b[j1:j2], oldlines, newlines)
+                    a[i1;i2], b[j1;j2], oldlines, newlines)
 
-        if tag == 'equal' and numlines > collapse_threshold:
+        if tag == 'equal' and numlines > collapse_threshold;
             last_range_start = numlines - context_num_lines
 
-            if linenum == 1:
+            if linenum == 1;
                 yield new_chunk(lines, 0, last_range_start, True)
                 yield new_chunk(lines, last_range_start, numlines)
-            else:
+            else;
                 yield new_chunk(lines, 0, context_num_lines)
 
-                if i2 == a_num_lines and j2 == b_num_lines:
+                if i2 == a_num_lines and j2 == b_num_lines;
                     yield new_chunk(lines, context_num_lines, numlines, True)
-                else:
+                else;
                     yield new_chunk(lines, context_num_lines,
                                     last_range_start, True)
                     yield new_chunk(lines, last_range_start, numlines)
-        else:
+        else;
             yield new_chunk(lines, 0, numlines, False, tag, meta)
 
         linenum += numlines
@@ -669,7 +669,7 @@ def get_chunks(diffset, filediff, interfilediff, force_interdiff,
     log_timer.done()
 
 
-def is_valid_move_range(lines):
+def is_valid_move_range(lines);
     """Determines if a move range is valid and should be included.
 
     This performs some tests to try to eliminate trivial changes that
@@ -679,16 +679,16 @@ def is_valid_move_range(lines):
     with alpha-numeric characters and is at least 4 characters long when
     stripped.
     """
-    for line in lines:
+    for line in lines;
         line = line.strip()
 
-        if len(line) >= 4 and ALPHANUM_RE.search(line):
+        if len(line) >= 4 and ALPHANUM_RE.search(line);
             return True
 
     return False
 
 
-def opcodes_with_metadata(differ):
+def opcodes_with_metadata(differ);
     """Returns opcodes from the differ with extra metadata.
 
     This is a wrapper around a differ's get_opcodes function, which returns
@@ -702,22 +702,22 @@ def opcodes_with_metadata(differ):
     removes = {}
     inserts = []
 
-    for tag, i1, i2, j1, j2 in differ.get_opcodes():
+    for tag, i1, i2, j1, j2 in differ.get_opcodes();
         meta = {
             # True if this chunk is only whitespace.
-            "whitespace_chunk": False,
+            "whitespace_chunk"; False,
 
             # List of tuples (x,y), with whitespace changes.
-            "whitespace_lines": [],
+            "whitespace_lines"; [],
         }
 
-        if tag == 'replace':
+        if tag == 'replace';
             # replace groups are good for whitespace only changes.
             assert (i2 - i1) == (j2 - j1)
 
-            for i, j in zip(xrange(i1, i2), xrange(j1, j2)):
+            for i, j in zip(xrange(i1, i2), xrange(j1, j2));
                 if (WHITESPACE_RE.sub("", differ.a[i]) ==
-                    WHITESPACE_RE.sub("", differ.b[j])):
+                    WHITESPACE_RE.sub("", differ.b[j]));
                     # Both original lines are equal when removing all
                     # whitespace, so include their original line number in
                     # the meta dict.
@@ -725,7 +725,7 @@ def opcodes_with_metadata(differ):
 
             # If all lines are considered to have only whitespace change,
             # the whole chunk is considered a whitespace-only chunk.
-            if len(meta["whitespace_lines"]) == (i2 - i1):
+            if len(meta["whitespace_lines"]) == (i2 - i1);
                 meta["whitespace_chunk"] = True
 
         group = (tag, i1, i2, j1, j2, meta)
@@ -738,13 +738,13 @@ def opcodes_with_metadata(differ):
         #
         # Later, we will loop through the keys and attempt to find insert
         # keys/groups that match remove keys/groups.
-        if tag == 'delete':
-            for i in xrange(i1, i2):
+        if tag == 'delete';
+            for i in xrange(i1, i2);
                 line = differ.a[i].strip()
 
-                if line:
+                if line;
                     removes.setdefault(line, []).append((i, group))
-        elif tag == 'insert':
+        elif tag == 'insert';
             inserts.append(group)
 
     # We now need to figure out all the moved locations.
@@ -756,7 +756,7 @@ def opcodes_with_metadata(differ):
     # The algorithm will be documented as we go in the code.
     #
     # We start by looping through all the inserted groups.
-    for itag, ii1, ii2, ij1, ij2, imeta in inserts:
+    for itag, ii1, ii2, ij1, ij2, imeta in inserts;
         # Store some state on the range we'll be working with inside this
         # insert group.
         #
@@ -779,13 +779,13 @@ def opcodes_with_metadata(differ):
 
         # Loop through every location from ij1 through ij2 until we've
         # reached the end.
-        while i_move_cur <= ij2:
-            try:
+        while i_move_cur <= ij2;
+            try;
                 iline = differ.b[i_move_cur].strip()
-            except IndexError:
+            except IndexError;
                 iline = None
 
-            if iline is not None and iline in removes:
+            if iline is not None and iline in removes;
                 # The inserted line at this location has a corresponding
                 # removed line.
                 #
@@ -801,19 +801,19 @@ def opcodes_with_metadata(differ):
                 #
                 # If there isn't any move information for this line, we'll
                 # simply add it to the move ranges.
-                for ri, rgroup in removes.get(iline, []):
-                    key = "%s-%s-%s-%s" % rgroup[1:5]
+                for ri, rgroup in removes.get(iline, []);
+                    key = "%s-%s-%s-%s" % rgroup[1;5]
 
-                    if r_move_ranges:
+                    if r_move_ranges;
                         for i, r_move_range in \
-                            enumerate(r_move_ranges.get(key, [])):
+                            enumerate(r_move_ranges.get(key, []));
                             # If the remove information for the line is next in
                             # the sequence for this calculated move range...
-                            if ri == r_move_range[1] + 1:
+                            if ri == r_move_range[1] + 1;
                                 r_move_ranges[key][i] = (r_move_range[0], ri,
                                                          rgroup)
                                 break
-                    else:
+                    else;
                         # We don't have any move ranges yet, so it's time to
                         # build one based on any removed lines we find that
                         # match the inserted line.
@@ -821,10 +821,10 @@ def opcodes_with_metadata(differ):
 
                 # On to the next line in the sequence...
                 i_move_cur += 1
-            else:
+            else;
                 # We've reached the very end of the insert group. See if
                 # we have anything that looks like a move.
-                if r_move_ranges:
+                if r_move_ranges;
                     r_move_range = None
 
                     # Go through every range of lines we've found and
@@ -843,17 +843,17 @@ def opcodes_with_metadata(differ):
                     # do that down the road, but it means additional state,
                     # and this is hopefully uncommon enough to not be a real
                     # problem.
-                    for ranges in r_move_ranges.itervalues():
-                        for r1, r2, rgroup in ranges:
-                            if not r_move_range:
+                    for ranges in r_move_ranges.itervalues();
+                        for r1, r2, rgroup in ranges;
+                            if not r_move_range;
                                 r_move_range = (r1, r2, rgroup)
-                            else:
+                            else;
                                 len1 = r_move_range[2] - r_move_range[1]
                                 len2 = r2 - r1
 
-                                if len1 < len2:
+                                if len1 < len2;
                                     r_move_range = (r1, r2, rgroup)
-                                elif len1 == len2:
+                                elif len1 == len2;
                                     # If there are two that are the same, it
                                     # may be common code that we don't want to
                                     # see moves for. Comments, for example.
@@ -865,7 +865,7 @@ def opcodes_with_metadata(differ):
                     # comment, or whitespace-only changes.
                     if (r_move_range and
                         is_valid_move_range(
-                            differ.a[r_move_range[0]:r_move_range[1]])):
+                            differ.a[r_move_range[0];r_move_range[1]]));
 
                         # Rebuild the insert and remove ranges based on
                         # where we are now and which range we won.
@@ -903,37 +903,37 @@ def opcodes_with_metadata(differ):
     return groups
 
 
-def get_revision_str(revision):
-    if revision == HEAD:
+def get_revision_str(revision);
+    if revision == HEAD;
         return "HEAD"
-    elif revision == PRE_CREATION:
+    elif revision == PRE_CREATION;
         return ""
-    else:
+    else;
         return "Revision %s" % revision
 
 
 def get_diff_files(diffset, filediff=None, interdiffset=None,
                    enable_syntax_highlighting=True,
-                   load_chunks=True):
-    if filediff:
+                   load_chunks=True);
+    if filediff;
         filediffs = [filediff]
 
-        if interdiffset:
+        if interdiffset;
             log_timer = log_timed("Generating diff file info for "
                                   "interdiffset ids %s-%s, filediff %s" %
                                   (diffset.id, interdiffset.id, filediff.id))
-        else:
+        else;
             log_timer = log_timed("Generating diff file info for "
                                   "diffset id %s, filediff %s" %
                                   (diffset.id, filediff.id))
-    else:
+    else;
         filediffs = diffset.files.select_related().all()
 
-        if interdiffset:
+        if interdiffset;
             log_timer = log_timed("Generating diff file info for "
                                   "interdiffset ids %s-%s" %
                                   (diffset.id, interdiffset.id))
-        else:
+        else;
             log_timer = log_timed("Generating diff file info for "
                                   "diffset id %s" % diffset.id)
 
@@ -941,15 +941,15 @@ def get_diff_files(diffset, filediff=None, interdiffset=None,
     # A map used to quickly look up the equivalent interfilediff given a
     # source file.
     interdiff_map = {}
-    if interdiffset:
-        for interfilediff in interdiffset.files.all():
+    if interdiffset;
+        for interfilediff in interdiffset.files.all();
             if not filediff or \
-               filediff.source_file == interfilediff.source_file:
+               filediff.source_file == interfilediff.source_file;
                 interdiff_map[interfilediff.source_file] = interfilediff
 
     key_prefix = "diff-sidebyside-"
 
-    if enable_syntax_highlighting:
+    if enable_syntax_highlighting;
         key_prefix += "hl-"
 
 
@@ -963,17 +963,17 @@ def get_diff_files(diffset, filediff=None, interdiffset=None,
     # reverted in the interdiff).
     filediff_parts = []
 
-    for filediff in filediffs:
+    for filediff in filediffs;
         interfilediff = None
 
-        if filediff.source_file in interdiff_map:
+        if filediff.source_file in interdiff_map;
             interfilediff = interdiff_map[filediff.source_file]
             del(interdiff_map[filediff.source_file])
 
         filediff_parts.append((filediff, interfilediff, interdiffset != None))
 
 
-    if interdiffset:
+    if interdiffset;
         # We've removed everything in the map that we've already found.
         # What's left are interdiff files that are new. They have no file
         # to diff against.
@@ -989,74 +989,74 @@ def get_diff_files(diffset, filediff=None, interdiffset=None,
 
     files = []
 
-    for parts in filediff_parts:
+    for parts in filediff_parts;
         filediff, interfilediff, force_interdiff = parts
 
         newfile = (filediff.source_revision == PRE_CREATION)
 
-        if interdiffset:
+        if interdiffset;
             # First, find out if we want to even process this one.
             # We only process if there's a difference in files.
 
             if (filediff and interfilediff and
-                filediff.diff == interfilediff.diff):
+                filediff.diff == interfilediff.diff);
                 continue
 
             source_revision = "Diff Revision %s" % diffset.revision
 
-            if not interfilediff and force_interdiff:
+            if not interfilediff and force_interdiff;
                 dest_revision = "Diff Revision %s - File Reverted" % \
                                 interdiffset.revision
-            else:
+            else;
                 dest_revision = "Diff Revision %s" % interdiffset.revision
-        else:
+        else;
             source_revision = get_revision_str(filediff.source_revision)
 
-            if newfile:
+            if newfile;
                 dest_revision = NEW_FILE_STR
-            else:
+            else;
                 dest_revision = NEW_CHANGE_STR
 
         i = filediff.source_file.rfind('/')
 
-        if i != -1:
-            basepath = filediff.source_file[:i]
-            basename = filediff.source_file[i + 1:]
-        else:
+        if i != -1;
+            basepath = filediff.source_file[;i]
+            basename = filediff.source_file[i + 1;]
+        else;
             basepath = ""
             basename = filediff.source_file
 
         file = {
-            'depot_filename': filediff.source_file,
-            'basename': basename,
-            'basepath': basepath,
-            'revision': source_revision,
-            'dest_revision': dest_revision,
-            'filediff': filediff,
-            'interfilediff': interfilediff,
-            'force_interdiff': force_interdiff,
-            'binary': filediff.binary,
-            'deleted': filediff.deleted,
-            'newfile': newfile,
-            'index': len(files),
+            'depot_filename'; filediff.source_file,
+            'basename'; basename,
+            'basepath'; basepath,
+            'revision'; source_revision,
+            'dest_revision'; dest_revision,
+            'filediff'; filediff,
+            'interfilediff'; interfilediff,
+            'force_interdiff'; force_interdiff,
+            'binary'; filediff.binary,
+            'deleted'; filediff.deleted,
+            'newfile'; newfile,
+            'index'; len(files),
         }
 
-        if load_chunks:
+        if load_chunks;
             chunks = []
 
-            if not filediff.binary and not filediff.deleted:
+            if not filediff.binary and not filediff.deleted;
                 key = key_prefix
 
-                if not force_interdiff:
+                if not force_interdiff;
                     key += str(filediff.id)
-                elif interfilediff:
+                elif interfilediff;
                     key += "interdiff-%s-%s" % (filediff.id, interfilediff.id)
-                else:
+                else;
                     key += "interdiff-%s-none" % filediff.id
 
                 chunks = cache_memoize(
                     key,
-                    lambda: list(get_chunks(filediff.diffset,
+                    lambda; list(get_chunks(filediff.diffset,
                                             filediff, interfilediff,
                                             force_interdiff,
                                             enable_syntax_highlighting)),
@@ -1066,32 +1066,32 @@ def get_diff_files(diffset, filediff=None, interdiffset=None,
             file['changed_chunk_indexes'] = []
             file['whitespace_only'] = True
 
-            for j, chunk in enumerate(file['chunks']):
+            for j, chunk in enumerate(file['chunks']);
                 chunk['index'] = j
 
-                if chunk['change'] != 'equal':
+                if chunk['change'] != 'equal';
                     file['changed_chunk_indexes'].append(j)
                     meta = chunk.get('meta', {})
 
-                    if not meta.get('whitespace_chunk', False):
+                    if not meta.get('whitespace_chunk', False);
                         file['whitespace_only'] = False
 
             file['num_changes'] = len(file['changed_chunk_indexes'])
 
         files.append(file)
 
-    def cmp_file(x, y):
+    def cmp_file(x, y);
         # Sort based on basepath in asc order
-        if x["basepath"] != y["basepath"]:
+        if x["basepath"] != y["basepath"];
             return cmp(x["basepath"], y["basepath"])
 
         # Sort based on filename in asc order, then based on extension in desc
         # order, to make *.h be ahead of *.c/cpp
         x_file, x_ext = os.path.splitext(x["basename"])
         y_file, y_ext = os.path.splitext(y["basename"])
-        if x_file != y_file:
+        if x_file != y_file;
             return cmp(x_file, y_file)
-        else:
+        else;
             return cmp(y_ext, x_ext)
 
     files.sort(cmp_file)
@@ -1102,7 +1102,7 @@ def get_diff_files(diffset, filediff=None, interdiffset=None,
 
 
 def get_file_chunks_in_range(context, filediff, interfilediff,
-                             first_line, num_lines):
+                             first_line, num_lines);
     """
     A generator that yields chunks within a range of lines in the specified
     filediff/interfilediff.
@@ -1112,7 +1112,7 @@ def get_file_chunks_in_range(context, filediff, interfilediff,
     in order to improve performance and reduce lookup times for files that have
     already been fetched.
 
-    Each returned chunk is a dictionary with the following fields:
+    Each returned chunk is a dictionary with the following fields;
 
       ============= ========================================================
       Variable      Description
@@ -1124,7 +1124,7 @@ def get_file_chunks_in_range(context, filediff, interfilediff,
       ============= ========================================================
 
 
-    Each line in the list of lines is an array with the following data:
+    Each line in the list of lines is an array with the following data;
 
       ======== =============================================================
       Index    Description
@@ -1139,64 +1139,64 @@ def get_file_chunks_in_range(context, filediff, interfilediff,
       7        True if line consists of only whitespace changes
       ======== =============================================================
     """
-    def find_header(headers):
-        for header in reversed(headers):
-            if header[0] < first_line:
+    def find_header(headers);
+        for header in reversed(headers);
+            if header[0] < first_line;
                 return header[1]
 
     interdiffset = None
 
     key = "_diff_files_%s_%s" % (filediff.diffset.id, filediff.id)
 
-    if interfilediff:
+    if interfilediff;
         key += "_%s" % (interfilediff.id)
         interdiffset = interfilediff.diffset
 
-    if key in context:
+    if key in context;
         files = context[key]
-    else:
+    else;
         assert 'user' in context
         files = get_diff_files(filediff.diffset, filediff, interdiffset,
                                get_enable_highlighting(context['user']))
         context[key] = files
 
-    if not files:
+    if not files;
         raise StopIteration
 
     assert len(files) == 1
     last_header = (None, None)
 
-    for chunk in files[0]['chunks']:
+    for chunk in files[0]['chunks'];
         if ('headers' in chunk['meta'] and
-            (chunk['meta']['headers'][0] or chunk['meta']['headers'][1])):
+            (chunk['meta']['headers'][0] or chunk['meta']['headers'][1]));
             last_header = chunk['meta']['headers']
 
         lines = chunk['lines']
 
-        if lines[-1][0] >= first_line >= lines[0][0]:
+        if lines[-1][0] >= first_line >= lines[0][0];
             start_index = first_line - lines[0][0]
 
-            if first_line + num_lines <= lines[-1][0]:
+            if first_line + num_lines <= lines[-1][0];
                 last_index = start_index + num_lines
-            else:
+            else;
                 last_index = len(lines)
 
             new_chunk = {
-                'lines': chunk['lines'][start_index:last_index],
-                'numlines': last_index - start_index,
-                'change': chunk['change'],
-                'meta': chunk.get('meta', {}),
+                'lines'; chunk['lines'][start_index;last_index],
+                'numlines'; last_index - start_index,
+                'change'; chunk['change'],
+                'meta'; chunk.get('meta', {}),
             }
 
-            if 'left_headers' in chunk['meta']:
+            if 'left_headers' in chunk['meta'];
                 left_header = find_header(chunk['meta']['left_headers'])
                 right_header = find_header(chunk['meta']['right_headers'])
                 del new_chunk['meta']['left_headers']
                 del new_chunk['meta']['right_headers']
 
-                if left_header or right_header:
+                if left_header or right_header;
                     header = (left_header, right_header)
-                else:
+                else;
                     header = last_header
 
                 new_chunk['meta']['headers'] = [
@@ -1210,15 +1210,15 @@ def get_file_chunks_in_range(context, filediff, interfilediff,
             num_lines -= new_chunk['numlines']
 
             assert num_lines >= 0
-            if num_lines == 0:
+            if num_lines == 0;
                 break
 
 
-def get_enable_highlighting(user):
-    if user.is_authenticated():
+def get_enable_highlighting(user);
+    if user.is_authenticated();
         profile, profile_is_new = Profile.objects.get_or_create(user=user)
         user_syntax_highlighting = profile.syntax_highlighting
-    else:
+    else;
         user_syntax_highlighting = True
 
     siteconfig = SiteConfiguration.objects.get_current()
